# -*- coding: utf-8 -*-
"""6_BostonHousing.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Oem9S3OBggURGPd71OuqSJI-DgX03OC_

# **Boston Housing**
- **Target** 
> - 주택가격 ('MEDV')

- **Feature**
> - 'CRIM': 범죄율
> - 'ZN' : 25,000 평방미터 거주지역 비율
> - 'INDUS' : 비소매상업지역의 비율
> - 'CHAS': 찰스강 경계에 위치하면 1, 아니면 0
> - 'NOX' : 일산화질소 농도
> - 'RM' : 방의 수
> - 'AGE': 1940년 이전 주택의 비율
> - 'DIS' : 직업센터와의 거리
> - 'RAD': 방사형 고속도록와의 거리
> - 'TAX' : 재산세율
> - 'PTRATIO' : 선생님과 학생의 비율
> - 'B' : 흑인 비율
> - 'LSTAT' : 하위계층의 비율
"""

# 6_BostonHousing_홍길동.ipynb

import pandas as pd

from keras.models import Sequential
from keras.layers import Dense

from sklearn.datasets import load_boston
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split

# hyper-parameter
MY_EPOCH = 50
MY_BATCH = 32

boston = load_boston()
boston

# 데이터와 타켓합쳐서 DF로 확인 출력
# 스케일링
# 나눈다  ==> 출력하는 코드
# 시퀀스생성 -> 덴스 -> 
# 서머리 ->
# 컴파일 => 최적화 : sgd, loss-> mse
# evalute 검증 -> loss -> 2% 이내

"""Q1: MY_EPOCH 하이퍼 파라미터를 0으로 바꾸고 실험을 반복하세요. 결과는?
속도?
loss?

Q2: 500개 뉴런을 가진 은닉층 두개를 마지막 단에 추가하고 실험을 반복하세요. 결과는?

Q3: Z-점수 정규화를 건너 뛰고 실험을 반복하세요. 결과는?

Q4: MY_BATCH 하이퍼 파라미터를 1로 바꾸고 실험을 반복하세요. 결과는?

Q5: 최적화 알고리즘을 sgd (경사하강법) 대신 adam(Adaptive Moment Estimation) 으로 바꾸고 실험을
반복하세요. 결과는?

Q6: 학습용 데이터의 하반부를 제거(1/2)하고 실험을 반복하세요. 결과는?

Q7: Boston Housing Dataset에서 RM (방의 수) 요소를 제거하고 실험을 반복하세요. 결과는?

Q8: 현재 집값을 예측하는 것에서, 집의 나이를 추측하는 것으로 바꾸어 보세요. 둘 중 어떤 문제가 손실값이
적은가요?
"""

