# -*- coding: utf-8 -*-
"""4_Keras_Housing.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1AaqpIHfMxqGNH_Zp1rYesxJzHROhh94y
"""

from keras.models import Sequential
from keras.layers import Dense

from sklearn.datasets import fetch_california_housing
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
import numpy as np
import pandas as pd

# Data Fetch 하기
housing = fetch_california_housing()
housing

X = housing.data
y = housing.target

#표준화
scaler = StandardScaler()
scaled_DB = scaler.fit_transform(X) # sc => numpy, raw => DF

scaled_DB

scaled_y = scaler.fit_transform(y.reshape(-1, 1)) # sc => numpy, raw => DF

housing_data = pd.DataFrame(scaled_DB, columns=housing.feature_names)
housing_data['Price'] = scaled_y

housing_data

#housing_data = housing_data.drop(['Latitude', 'Longitude'], axis=1) # 0은 열, 1은 행

housing_data

X = housing_data.iloc[:, :-1]
y = housing_data.iloc[:, -1]

X

y

# 학습(훈련)과 데이터(검증)를 나눔 70 : 30
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)

print('X_train shape : ', X_train.shape)
print('y_train shape : ', y_train.shape) #선형 -> Linear, 분류 -> sigmoid
print('X_test shape : ', X_test.shape)
print('y_test shape : ', y_test.shape)

model = Sequential()
model.add(Dense(32, activation='relu', input_dim=8))
model.add(Dense(100, activation='relu'))
model.add(Dense(100, activation='relu'))
model.add(Dense(1, activation='linear'))
model.summary()

model.compile(optimizer='sgd', loss='mse', metrics=['accuracy'])

# 학습
model.fit(X_train, y_train, epochs=70, batch_size=32, verbose=1)  #epochs는 반복 횟수, batch_size는 메모리에 올릴 개수

score = model.evaluate(X_test, y_test, verbose=1)
print('Loss : ',score[0])
print('Accuaracy', score[1])

"""1) 위도, 경도를 없앰<br>
2) 값의 편차가 크지 않도록 함 : 스케일링(StandardScaling)

1) 검증 데이터의 Loss가 얼마인지 확인하세요: loss: 0.3880 - accuracy: 0.0050<br>
2) X만 스케일링하지 않고, y도 스케일링하면 Loss가 좋아지는가?: 그렇다<br>
3) Loss가 가장 적게 나오는 사람은?<br>
"""