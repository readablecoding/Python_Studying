# -*- coding: utf-8 -*-
"""10_Cifar10_MNIST.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ulRb_XjRB6LleVTx6M7Kk-lK4wDo1Oua
"""

!pip install tensorflow-gpu==2.0.0

from keras.datasets import cifar10
from keras.models import Sequential
from keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout
from keras.optimizers import Adam
from keras.utils import to_categorical

# hyper parameter 
WIDTH, HEIGHT, CHANNEL = 32, 32, 3

MYEPOCH = 70
MYBATCH = 50

# Data Load
(X_train, y_train), (X_test, y_test) = cifar10.load_data()

X_train.shape, y_train.shape, X_test.shape, y_test.shape

y_train[0][0]

labels = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']
labels[y_train[0][0]]

# 0번 그림 출력해보기
import matplotlib.pyplot as plt
plt.rcParams["figure.figsize"] = (2, 2)
plt.imshow(X_train[3])
plt.axis('off')
plt.title('Correct : ' + labels[y_train[3][0]]) # 열은 0으로 고정됨
plt.show()

# Scaling : 학습을 잘 하기 위해 편차를 줄이기 위해 스케일링을 한다
X_train = X_train.astype('float32')
X_test = X_test.astype('float32')

X_train = X_train / 255.0
X_test = X_test / 255.0

# y 값을 One-hot Encoding (0 ~ 9) : 원핫인코딩을 했으므로 'categorical_crossentropy'
# 만약 아래 두 코드를 삭제하면 'sparse_categorical_crossentropy' 사용하여 compile 함 
y_train = to_categorical(y_train)
y_test = to_categorical(y_test)

"""### 1) categoricl_crossentropy
- 원-핫-인코딩된 레이블로 cross entropy를 계산
  (target과 output의 shape가 같아야 함) 
  
### 2) sparse_categorical_crossentropy
- 한 개 있는 정답 레이블을 가지고 있음
- MNIST의 경우 : 정답 레이블이 0 ~ 9로, 하나의 열에 정답 레이블이 정수로 표시되어 있으므로 sparce_categorical_crossentropy
"""

from keras.callbacks import EarlyStopping
early_stopping = EarlyStopping(monitor='val_accuracy', patience=5) # val_accuracy를 모니터링하다 5회 증가하지 않으면 fit 종료

# Model - compile - fit - 그림 -

model = Sequential()

model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(WIDTH, HEIGHT, CHANNEL)))
model.add(MaxPool2D(pool_size=(2, 2)))
model.add(Dropout(0.25))

model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))
model.add(MaxPool2D(pool_size=(2, 2)))
model.add(Dropout(0.25))

model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))
model.add(MaxPool2D(pool_size=(2, 2)))
model.add(Dropout(0.25))

model.add(Flatten())
model.add(Dense(256, activation='relu'))
model.add(Dense(128, activation='relu'))
model.add(Dropout(0.5))

model.add(Dense(10, activation='softmax'))

model.summary()

model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])

X_train.shape, y_train.shape

# fit

hist = model.fit(X_train, y_train, 
                 batch_size=MYBATCH, 
                 epochs=MYEPOCH, 
                 verbose=1, 
                 validation_split=0.2,
                 callbacks=[early_stopping])

# 학습 과정을 그래프로 그려보기

import matplotlib.pyplot as plt
plt.rcParams["figure.figsize"] = (5, 5)


fig, loss_ax = plt.subplots()
acc_ax = loss_ax.twinx()

loss_ax.plot(hist.history['loss'], 'y', label = 'train loss')
loss_ax.plot(hist.history['val_loss'], 'r', label = 'val loss')

acc_ax.plot(hist.history['accuracy'], 'b', label = 'train acc')
acc_ax.plot(hist.history['val_accuracy'], 'g', label = 'val acc')

loss_ax.set_xlabel('Epoch')
loss_ax.set_ylabel('Loss')

acc_ax.set_ylabel('Accuracy')

loss_ax.legend(loc='upper left')
acc_ax.legend(loc='lower left')

plt.show()

import numpy as np
yhat = model.predict(X_test, batch_size=32)
print("0 데이터 예측 :", np.argmax(yhat[0]))
print("0 정답 :", y_test[0][0])

yhat[0]

# 잘못 예측한 데이터 확인

import matplotlib.pyplot as plt

plt.rcParams["figure.figsize"] = (12, 15)
row = 5
col = 5

f, axarr = plt.subplots(row, col)
cnt = 0
i = 0

while cnt < (row * col) :
  if y_test[i][0] == np.argmax(yhat[i]):
    i = i + 1
    continue
  
  #답을 못 맞추었으므로 그림을 그려봄
  sub_plot = axarr[(int(cnt/row), int(cnt%col))]
  sub_plot.axis('off')
  sub_plot.imshow(X_test[i].reshape(WIDTH, HEIGHT, CHANNEL)) # 가로, 세로, 컬러
  tmp = "C : " + labels[np.argmax(y_test[i])] + ', P : ' + labels[np.argmax(yhat[i])] # C는 정답, P는 예상
  sub_plot.set_title(tmp)

  i = i + 1
  cnt = cnt + 1
  
plt.show()

score = model.evaluate(X_test, y_test, verbose=1)
print('loss : ', score[0])
print('accuracy : ', score[1])