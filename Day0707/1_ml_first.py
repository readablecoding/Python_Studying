# -*- coding: utf-8 -*-
"""1_ML_First.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1M3tTaeDTzjRFVf5xnS0zQ5Dowl2v56vT

## **선형회귀 기초**
1.   파이썬으로 Cost Function 그래프 그리기
2.   GD(Gradient Descent): 경사하강 알고리즘 직접 구현하기
"""

# 입력 x, 출력 y가 정해진 상태라면 y = Wx + b => a : 1, b : 0
# y = 2x + 0 : weight

def cost(W, x, y):
  s = 0
  for i in range(len(x)):
    s +=  (W * x[i] - y[i]) ** 2
    return s / len(x)
    

x = [1., 2., 3.] #입력, 독립변수, Feature
y = [1., 4., 6.] #출력, 종속변수

W_val = []
cost_val = []

for i in range(-30, 71):
  W = 0.1 * i
  c = cost(W, x, y)

  W_val.append(W)
  cost_val.append(c)

#-----------------------------------Cost Function 그래프 작성
import matplotlib.pyplot as plt

plt.plot(W_val, cost_val)
plt.ylabel('Cost')
plt.xlabel('Weight')
plt.show()


#cost <= 비용이 최소화되는 하나의 선. 즉,입력 x와 출력 y를 가장 잘 대변하는 하나의 선을 찾는 것이 선형회귀이며 찾는 방법 중 
#가장 많이 사용하는 방식이 오차를 찾아 오차를 최소화하는 것이다
# y hat
# (실제 값 - 추측 값)의 제곱을 전체 합 =>  2차 방정식으로 바뀜, 미분
# GD: 경사 하강법
# Learning rate: 학습률 (W를 조절하는 법)
# 사람이 지정한 파라미터를 하이퍼 파라미터라고 한다
# [(실제값 - 추측값)^2]의 합 / 개수

def gradient(W, X, y):
  tmp = []
  for i in range(len(x)):
    tmp.append(W * X[i] - y[i])

  s = 0
  for i in range(len(x)):
    s += tmp[i] * X[i]
  
  return s / len(x)



X = [1., 2., 3.]
y = [1., 2., 3.]
W = -100
learning_rate = 0.005


for i in range(1000):
  g = gradient(W, X, y)
  W = W - g * learning_rate
  
  if i % 20 == 19:
    print('{:4} => {:17.12f}{:12.8f}'.format(i+1, g, W))

# Cost Function + Gradient Descent 알고리즘을 함께
def cost(W, X, y):
  s = 0
  for i in range(len(X)):
    s +=  (W * X[i] - y[i]) ** 2
    return s / len(X)


def gradient(W, X, y):
  tmp = []
  for i in range(len(X)):
    tmp.append(W * X[i] - y[i])

  s = 0
  for i in range(len(X)):
    s += tmp[i] * X[i]
  
  return s / len(X)



X = [1., 2., 3.]
y = [2., 4., 6.]
W = 100
learning_rate = 0.01


for i in range(1000):
  g = gradient(W, X, y)
  c = cost(W, X, y)
  W = W - g * learning_rate
  
  if i % 20 == 19:
    print('{:4} => {:17.12f} {:12.8f} {:12.8f}'.format(i+1, g, c, W))

"""# **Machine Learning**
- Tensorflow: 머신러닝
- Keras: 딥러닝
- Pytorch
"""

print('Hello World')

import tensorflow
tensorflow.__version__

!pip list #!가 붙으면 cmd 통함

!pip uninstall tensorflow
!pip install tensorflow==1.15 #설치 후 런타임 다시 시작할 것

import tensorflow as tf

tf.__version__

import tensorflow as tf

import matplotlib.pyplot as plt

x = [1, 2, 3]
y = [1, 2, 3]

w = tf.placeholder(tf.float32)
hypothesis = x * w

cost = tf.reduce_mean(tf.square(hypothesis - y)) #오차 제곱의 평균

