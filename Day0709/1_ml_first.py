# -*- coding: utf-8 -*-
"""1_ML_First.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1M3tTaeDTzjRFVf5xnS0zQ5Dowl2v56vT

## **선형회귀 기초**
1.   파이썬으로 Cost Function 그래프 그리기
2.   GD(Gradient Descent): 경사하강 알고리즘 직접 구현하기
"""

# 입력 x, 출력 y가 정해진 상태라면 y = Wx + b => a : 1, b : 0
# y = 2x + 0 : weight

def cost(W, x, y):
  s = 0
  for i in range(len(x)):
    s +=  (W * x[i] - y[i]) ** 2
    return s / len(x)
    

x = [1., 2., 3.] #입력, 독립변수, Feature
y = [1., 4., 6.] #출력, 종속변수

W_val = []
cost_val = []

for i in range(-30, 71):
  W = 0.1 * i
  c = cost(W, x, y)

  W_val.append(W)
  cost_val.append(c)

#-----------------------------------Cost Function 그래프 작성
import matplotlib.pyplot as plt

plt.plot(W_val, cost_val)
plt.ylabel('Cost')
plt.xlabel('Weight')
plt.show()


#cost <= 비용이 최소화되는 하나의 선. 즉,입력 x와 출력 y를 가장 잘 대변하는 하나의 선을 찾는 것이 선형회귀이며 찾는 방법 중 
#가장 많이 사용하는 방식이 오차를 찾아 오차를 최소화하는 것이다
# y hat
# (실제 값 - 추측 값)의 제곱을 전체 합 =>  2차 방정식으로 바뀜, 미분
# GD: 경사 하강법
# Learning rate: 학습률 (W를 조절하는 법)
# 사람이 지정한 파라미터를 하이퍼 파라미터라고 한다
# [(실제값 - 추측값)^2]의 합 / 개수

def gradient(W, X, y):
  tmp = []
  for i in range(len(x)):
    tmp.append(W * X[i] - y[i])

  s = 0
  for i in range(len(x)):
    s += tmp[i] * X[i]
  
  return s / len(x)



X = [1., 2., 3.]
y = [1., 2., 3.]
W = -100
learning_rate = 0.005


for i in range(1000):
  g = gradient(W, X, y)
  W = W - g * learning_rate
  
  if i % 20 == 19:
    print('{:4} => {:17.12f}{:12.8f}'.format(i+1, g, W))

# Cost Function + Gradient Descent 알고리즘을 함께
def cost(W, X, y):
  s = 0
  for i in range(len(X)):
    s +=  (W * X[i] - y[i]) ** 2
    return s / len(X)


def gradient(W, X, y):
  tmp = []
  for i in range(len(X)):
    tmp.append(W * X[i] - y[i])

  s = 0
  for i in range(len(X)):
    s += tmp[i] * X[i]
  
  return s / len(X)



X = [1., 2., 3.]
y = [2., 4., 6.]
W = 100
learning_rate = 0.01


for i in range(1000):
  g = gradient(W, X, y)
  c = cost(W, X, y)
  W = W - g * learning_rate
  
  if i % 20 == 19:
    print('{:4} => {:17.12f} {:12.8f} {:12.8f}'.format(i+1, g, c, W))

"""#  **단변량 데이터의 LinearRegression**

- 사이킷 런을 이용
"""

from sklearn.linear_model import LinearRegression
import numpy as np
import matplotlib.pyplot as plt


### 데이터 준비(데이터 분석, 전처리) : 입력, csv, 온라인으로 제공되는 데이터를 사용

X = np.array([[1], [3], [2], [5], [4], [8], [1], [6], [3], [7]])
y = np.array([4, 2, 3, 6, 6, 9, 8, 9, 5, 8])

### 준비된 데이터로 시각화해보기



### 모델 준비
model = LinearRegression()

### 학습(fitting)
model.fit(X, y)  # y = Wx + b

### 평가(evaluate)
plt.plot(X, y, 'o')
plt.plot(X, model.predict(X))
plt.show()

### 예측(predict)
X_temp = [[7]]

y_temp = model.predict(X_temp)
print(y_temp)

#사이킷 런을 이용한 선형회귀-2 

from sklearn.linear_model import LinearRegression
import numpy as np
import matplotlib.pyplot as plt


## 데이터 준비
X = 10 * np.random.rand(100, 1)
y = 2.1 * X + 5.5 * np.random.rand(100, 1)



### 모델 준비
model = LinearRegression()

### 학습(fitting)
model.fit(X, y)  # y = Wx + b

### 시각화하기
plt.plot(X, y.reshape(-1, 1), 'o')
plt.plot(X, model.predict(X))
plt.show()

### 임의의 X를 만들어 예측한 값을 출력하시오
X_temp = [[7.7]]
y_temp = model.predict(X_temp)
print(y_temp)

# 문제: 키(170)를 입력하면 몸무게를 예측하는 선형회귀문제를 만드시오
'''raw_data = {
    'Height' : [165.67, 171.63, 169.5, 168.22, 183.5],
    'Weight' : [50.4, 58.45, 52.34, 50.5, 71.34]
}
'''

from sklearn.linear_model import LinearRegression
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

## 데이터 준비
raw_data = {
    'Height' : [165.67, 171.63, 169.5, 168.22, 183.5],
    'Weight' : [50.4, 58.45, 52.34, 50.5, 71.34]
}


X = np.array(raw_data['Height']).reshape(-1, 1) #행은 모르겠고 1열로 만든다
y = raw_data['Weight']


### 모델 준비
model = LinearRegression()

### 학습(fitting)
model.fit(X, y)  # y = Wx + b

### 시각화하기
plt.plot(X, y, 'o')
plt.plot(X, model.predict(X))
plt.show()

### 임의의 X를 만들어 예측한 값을 출력하시오
X_temp = [[170]]
y_temp = model.predict(X_temp)
print(y_temp)

from google.colab import files
uploaded = files.upload()

# 사이킷 런을 이용한 집값 예측

import numpy as np
import pandas as pd
from sklearn.linear_model import LinearRegression

raw_data = pd.read_csv("manhattan.csv")
raw_data

X = raw_data[['bedrooms','bathrooms','size_sqft',	'min_to_subway',	'floor',	'building_age_yrs',	'no_fee',	'has_roofdeck',	'has_washer_dryer',	'has_doorman',	'has_elevator',	'has_dishwasher',	'has_patio',	'has_gym']]
y = raw_data['rent']

### 모델 준비
model = LinearRegression()

### 학습(fitting)
model.fit(X, y)  # y = Wx + b

my_house = [[1, 1, 650, 15, 1, 98, 1, 0, 1, 0, 0, 1, 1, 0]]
house_fee = model.predict(my_house)
print(house_fee)

"""#로지스틱 회귀
- 판별(Classfication)
- 학습 -> 함수 -> 확률(0.1, 0.3, 0.6)
- 붓꽃(Iris) 3종류 => 4(꽃잎의 길이, 꽃잎의 폭, 꽃받침길이, 꽃받침폭)
"""

from sklearn.datasets import load_iris
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split
import pandas as pd

iris = load_iris()

iris

iris_data = iris.data       # 전체 데이터에서 iris의 Feature 부분만 가져옴(numpy.ndarray로 추출)
iris_target = iris.target   # 전체 데이터에서 iris의 Target 부분만 가져옴

##붓꽃 데이터를 편하게 하기 위해 DataFrame으로 변경
iris_df = pd.DataFrame(iris_data, columns = iris.feature_names)
iris_df['label'] = iris_target

iris_df

# 학습과 테스트를 나눔 80 : 20
X_train, X_test, y_train, y_test = train_test_split(iris_data, iris_target, test_size = 0.2, random_state = 10)

# 모델 생성
model = DecisionTreeClassifier(random_state = 10)

# 모델 학습
model.fit(X_train, y_train)

# 예측
y_pred = model.predict(X_test)

# 평가 : 학습이 얼마나 잘되었는지 평가해봄

from sklearn.metrics import accuracy_score
print(accuracy_score(y_test, y_pred))

"""## [과제] 캘리포니아 집값 데이터 셋을 읽어 사이킷 런을 이용하여 선형회귀로 예측프로그램을 작성하시오"""

from sklearn.datasets import fetch_california_housing
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
import numpy as np
import pandas as pd

housing = fetch_california_housing()
housing

housing_data = housing.data
housing_target = housing.target

#데이터를 편하게 하기 위해 DataFrame으로 변경
housing_df = pd.DataFrame(housing_data, columns=  housing.feature_names)
housing_df['Price'] = housing_target
housing_df

# 학습과 데이터를 나눔 80 : 20
X_train, X_test, y_train, y_test = train_test_split(housing_data, housing_target, test_size = 0.2, random_state = 10)

# 모델 생성
model = LinearRegression()

# 모델 학습
model.fit(X_train, y_train)

#예측
y_pred = model.predict(X_test)

# 평가: 학습이 얼마나 잘되었는지 평가
from sklearn.metrics import mean_squared_error, r2_score

# Coefficient: 가중치 계수
print('Coefficient : \n', model.coef_)

# MSE(오차 평가)
print('Mean Squared Error : %.2f' % mean_squared_error(y_test, y_pred))

# 결정계수가(Coefficient of determination) 1이면 완벽
print('결정계수 : %.2f' % r2_score(y_test, y_pred))

"""# **Machine Learning**
- Tensorflow: 머신러닝
- Keras: 딥러닝
- Pytorch
"""





print('Hello World')

import tensorflow
tensorflow.__version__

!pip list #!가 붙으면 cmd 통함

!pip uninstall tensorflow
!pip install tensorflow==1.15 #설치 후 런타임 다시 시작할 것

import tensorflow as tf

tf.__version__

import tensorflow as tf

import matplotlib.pyplot as plt

x = [1, 2, 3]
y = [1, 2, 3]

w = tf.placeholder(tf.float32)
hypothesis = x * w

cost = tf.reduce_mean(tf.square(hypothesis - y)) #오차 제곱의 평균